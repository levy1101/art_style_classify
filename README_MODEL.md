# ğŸ“š PHÃ‚N LOáº I PHONG CÃCH NGHá»† THUáº¬T Báº°NG DEEP LEARNING

---

## Má»¤C Lá»¤C

1. [GIá»šI THIá»†U & Má»¤C TIÃŠU](#1-introduction-objectives)
2. [Tá»”NG QUAN KIáº¾N TRÃšC & LUá»’NG Xá»¬ LÃ](#2-overall-architecture-workflow)
3. [Cáº¤U TRÃšC THÆ¯ Má»¤C & Ã NGHÄ¨A CÃC FILE](#3-directory-structure-file-meanings)
4. [CÃ€I Äáº¶T MÃ”I TRÆ¯á»œNG & CHUáº¨N Bá»Š PHáº¦N Cá»¨NG](#4-environment-setup-hardware-preparation)
5. [CHUáº¨N Bá»Š Dá»® LIá»†U & Xá»¬ LÃ Lá»–I Dá»® LIá»†U](#5-data-preparation-error-handling)
6. [HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG CHO NGÆ¯á»œI DÃ™NG CUá»I](#6-end-user-usage-guide)
7. [HÆ¯á»šNG DáºªN CHO DEVELOPER & Má» Rá»˜NG](#7-developer-guide-extensions)
8. [GIáº¢I THÃCH CHI TIáº¾T Tá»ªNG FILE & LUá»’NG Xá»¬ LÃ](#8-detailed-file-explanations-processing-flows)
    - [constants.py](#constants.py)
    - [data_collector.py](#data_collector.py)
    - [train_model.py](#train_model.py)
    - [test_model.py](#test_model.py)
    - [01_setup.bat](#01_setup.bat)
    - [02_run_train.bat](#02_run_train.bat)
    - [03_run_test.bat](#03_run_test.bat)
    - [requirements.txt](#requirements.txt)
9. [QUY TRÃŒNH HUáº¤N LUYá»†N, KIá»‚M TRA & BÃO CÃO Káº¾T QUáº¢](#9-training-testing-result-reporting-process)
10. [VÃ Dá»¤ Äáº¦U RA, LOG, CONFUSION MATRIX, SAMPLE PREDICTION](#10-example-outputs-logs-confusion-matrix-sample-prediction)
11. [TROUBLESHOOTING & PERFORMANCE TUNING](#11-troubleshooting-performance-tuning)
12. [BEST PRACTICES & QUáº¢N LÃ MÃ”I TRÆ¯á»œNG](#12-best-practices-environment-management)
13. [TÃ€I LIá»†U THAM KHáº¢O, LIÃŠN Há»†, ÄÃ“NG GÃ“P](#13-references-contact-contributions)
14. [SÆ  Äá»’ CHI TIáº¾T CÃC LUá»’NG Xá»¬ LÃ TRONG CODE](#14-detailed-code-flow-diagrams)

---

<a id="1-introduction-objectives"></a>
## 1. GIá»šI THIá»†U & Má»¤C TIÃŠU

### Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n loáº¡i phong cÃ¡ch nghá»‡ thuáº­t sá»­ dá»¥ng máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN) vá»›i mÃ´ hÃ¬nh Xception (transfer learning). Há»‡ thá»‘ng nháº­n diá»‡n 5 phong cÃ¡ch: Baroque, Expressionism, Cubism, Japanese Art, Art Nouveau Modern. á»¨ng dá»¥ng thá»±c táº¿: phÃ¢n loáº¡i áº£nh nghá»‡ thuáº­t, há»— trá»£ báº£o tÃ ng, gallery, nghiÃªn cá»©u lá»‹ch sá»­ nghá»‡ thuáº­t, xÃ¢y dá»±ng app nháº­n diá»‡n tá»± Ä‘á»™ng.

Dá»± Ã¡n sá»­ dá»¥ng ká»¹ thuáº­t há»c mÃ¡y sÃ¢u Ä‘á»ƒ phÃ¢n tÃ­ch cÃ¡c Ä‘áº·c trÆ°ng thá»‹ giÃ¡c cá»§a tÃ¡c pháº©m nghá»‡ thuáº­t. MÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u WikiArt, má»™t bá»™ dá»¯ liá»‡u lá»›n chá»©a hÃ ng nghÃ¬n bá»©c tranh tá»« cÃ¡c phong cÃ¡ch khÃ¡c nhau. Viá»‡c sá»­ dá»¥ng transfer learning tá»« mÃ´ hÃ¬nh Xception Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn ImageNet giÃºp mÃ´ hÃ¬nh há»c nhanh hÆ¡n vÃ  Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n so vá»›i viá»‡c huáº¥n luyá»‡n tá»« Ä‘áº§u.

### Má»¥c tiÃªu

- Tá»± Ä‘á»™ng nháº­n diá»‡n phong cÃ¡ch nghá»‡ thuáº­t tá»« áº£nh.
- Dá»… sá»­ dá»¥ng cho ngÆ°á»i dÃ¹ng cuá»‘i (batch file) vÃ  dá»… má»Ÿ rá»™ng cho developer (script Python).
- Quáº£n lÃ½ dá»¯ liá»‡u, mÃ´ hÃ¬nh, log táº­p trung qua file `constants.py`.
- Há»— trá»£ GPU, tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ huáº¥n luyá»‡n vÃ  kiá»ƒm tra.
- CÃ³ thá»ƒ má»Ÿ rá»™ng thÃªm class, mÃ´ hÃ¬nh, hoáº·c tÃ­ch há»£p vÃ o há»‡ thá»‘ng lá»›n hÆ¡n.

Má»¥c tiÃªu chÃ­nh lÃ  táº¡o ra má»™t cÃ´ng cá»¥ dá»… sá»­ dá»¥ng nhÆ°ng máº¡nh máº½, cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o cÃ¡c á»©ng dá»¥ng thá»±c táº¿ nhÆ° á»©ng dá»¥ng di Ä‘á»™ng nháº­n diá»‡n nghá»‡ thuáº­t, há»‡ thá»‘ng quáº£n lÃ½ bá»™ sÆ°u táº­p, hoáº·c cÃ´ng cá»¥ nghiÃªn cá»©u tá»± Ä‘á»™ng.

---

<a id="2-overall-architecture-workflow"></a>
## 2. Tá»”NG QUAN KIáº¾N TRÃšC & LUá»’NG Xá»¬ LÃ

### SÆ¡ Ä‘á»“ tá»•ng quan

```mermaid
graph TD
    A[Chuáº©n bá»‹ dá»¯ liá»‡u] --> B[Chia train/validate/test]
    B --> C[Tiá»n xá»­ lÃ½ & Augmentation]
    C --> D[Huáº¥n luyá»‡n mÃ´ hÃ¬nh]
    D --> E[LÆ°u mÃ´ hÃ¬nh & log]
    E --> F[Kiá»ƒm tra mÃ´ hÃ¬nh]
    F --> G[BÃ¡o cÃ¡o káº¿t quáº£]
```

### Luá»“ng xá»­ lÃ½ chÃ­nh

1. Kiá»ƒm tra dá»¯ liá»‡u gá»‘c vÃ  dá»¯ liá»‡u Ä‘Ã£ chia
2. Chia dá»¯ liá»‡u tá»± Ä‘á»™ng náº¿u cáº§n
3. Tiá»n xá»­ lÃ½ áº£nh, augmentation
4. XÃ¢y dá»±ng mÃ´ hÃ¬nh Xception, thÃªm cÃ¡c lá»›p custom
5. Huáº¥n luyá»‡n 2 giai Ä‘oáº¡n (freeze/unfreeze)
6. LÆ°u mÃ´ hÃ¬nh, log tá»«ng láº§n cháº¡y
7. Kiá»ƒm tra mÃ´ hÃ¬nh, xuáº¥t bÃ¡o cÃ¡o, confusion matrix, vÃ­ dá»¥ dá»± Ä‘oÃ¡n

Luá»“ng xá»­ lÃ½ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a tá»‘i Ä‘a, tá»« viá»‡c chuáº©n bá»‹ dá»¯ liá»‡u Ä‘áº¿n Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh. Äiá»u nÃ y giÃºp ngÆ°á»i dÃ¹ng cuá»‘i cÃ³ thá»ƒ cháº¡y toÃ n bá»™ quy trÃ¬nh chá»‰ vá»›i vÃ i cÃº click, trong khi developer cÃ³ thá»ƒ tÃ¹y chá»‰nh tá»«ng bÆ°á»›c.

---

<a id="3-directory-structure-file-meanings"></a>
## 3. Cáº¤U TRÃšC THÆ¯ Má»¤C & Ã NGHÄ¨A CÃC FILE

```text
ttnt/
â”‚
â”œâ”€ kaggle/
â”‚   â”œâ”€ input/
â”‚   â”‚   â””â”€ wikiart/
â”‚   â”‚       â”œâ”€ Baroque/
â”‚   â”‚       â”œâ”€ Expressionism/
â”‚   â”‚       â”œâ”€ Cubism/
â”‚   â”‚       â”œâ”€ Japanese_Art/
â”‚   â”‚       â””â”€ Art_Nouveau_Modern/
â”‚   â””â”€ working/
â”‚       â””â”€ art_styles/
â”‚           â”œâ”€ train/[class]/
â”‚           â”œâ”€ validate/[class]/
â”‚           â””â”€ test/[class]/
â”œâ”€ app_log/           # Log huáº¥n luyá»‡n, má»—i láº§n cháº¡y táº¡o file riÃªng
â”œâ”€ train_model.py     # Script huáº¥n luyá»‡n, lÆ°u mÃ´ hÃ¬nh, log
â”œâ”€ test_model.py      # Script kiá»ƒm tra mÃ´ hÃ¬nh, xuáº¥t bÃ¡o cÃ¡o
â”œâ”€ data_collector.py  # Script chia dá»¯ liá»‡u tá»± Ä‘á»™ng
â”œâ”€ constants.py       # ÄÆ°á»ng dáº«n, háº±ng sá»‘ dÃ¹ng chung
â”œâ”€ 01_setup.bat       # Kiá»ƒm tra dá»¯ liá»‡u, hÆ°á»›ng dáº«n táº£i
â”œâ”€ 02_run_train.bat   # Tá»± Ä‘á»™ng huáº¥n luyá»‡n
â”œâ”€ 03_run_test.bat    # Tá»± Ä‘á»™ng kiá»ƒm tra mÃ´ hÃ¬nh
â”œâ”€ requirements.txt   # ThÆ° viá»‡n Python
â””â”€ README.md          # HÆ°á»›ng dáº«n chi tiáº¿t
```

### Ã nghÄ©a cÃ¡c file/folder

- **kaggle/input/wikiart/**: Dá»¯ liá»‡u gá»‘c, má»—i class lÃ  má»™t thÆ° má»¥c áº£nh
- **kaggle/working/art_styles/**: Dá»¯ liá»‡u Ä‘Ã£ chia train/validate/test
- **app_log/**: LÆ°u log tá»«ng láº§n huáº¥n luyá»‡n (theo timestamp)
- **train_model.py**: Huáº¥n luyá»‡n mÃ´ hÃ¬nh, lÆ°u log, tá»± Ä‘á»™ng chia dá»¯ liá»‡u náº¿u cáº§n
- **test_model.py**: Kiá»ƒm tra mÃ´ hÃ¬nh, xuáº¥t bÃ¡o cÃ¡o, confusion matrix, vÃ­ dá»¥ dá»± Ä‘oÃ¡n
- **data_collector.py**: Chia dá»¯ liá»‡u tá»« thÆ° má»¥c gá»‘c thÃ nh train/validate/test cho tá»«ng class
- **constants.py**: Quáº£n lÃ½ Ä‘Æ°á»ng dáº«n, tÃªn file, class, háº±ng sá»‘ dÃ¹ng chung cho toÃ n bá»™ project
- **01_setup.bat**: Kiá»ƒm tra dá»¯ liá»‡u Ä‘Ã£ chia, hÆ°á»›ng dáº«n táº£i náº¿u thiáº¿u
- **02_run_train.bat**: Tá»± Ä‘á»™ng kiá»ƒm tra Python, táº¡o venv, cÃ i thÆ° viá»‡n, huáº¥n luyá»‡n mÃ´ hÃ¬nh
- **03_run_test.bat**: Tá»± Ä‘á»™ng kiá»ƒm tra Python, táº¡o venv, cÃ i thÆ° viá»‡n, kiá»ƒm tra mÃ´ hÃ¬nh
- **requirements.txt**: Danh sÃ¡ch thÆ° viá»‡n Python cáº§n thiáº¿t
- **README.md**: HÆ°á»›ng dáº«n chi tiáº¿t, tÃ i liá»‡u dá»± Ã¡n

Cáº¥u trÃºc thÆ° má»¥c Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ dá»… quáº£n lÃ½ vÃ  má»Ÿ rá»™ng. Viá»‡c tÃ¡ch biá»‡t dá»¯ liá»‡u gá»‘c vÃ  dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ giÃºp trÃ¡nh lÃ m há»ng dá»¯ liá»‡u ban Ä‘áº§u.

---

<a id="4-environment-setup-hardware-preparation"></a>
## 4. CÃ€I Äáº¶T MÃ”I TRÆ¯á»œNG & CHUáº¨N Bá»Š PHáº¦N Cá»¨NG

### YÃªu cáº§u pháº§n cá»©ng

- Windows 10/11, RAM >= 8GB, khuyáº¿n nghá»‹ cÃ³ GPU (NVIDIA, CUDA >= 11)
- Náº¿u dÃ¹ng CPU: thá»i gian huáº¥n luyá»‡n lÃ¢u hÆ¡n, váº«n cháº¡y Ä‘Æ°á»£c

### CÃ i Ä‘áº·t Python & mÃ´i trÆ°á»ng áº£o

1. **CÃ i Python >=3.8**
    - Táº£i táº¡i <https://www.python.org/downloads/>
    - Xem video hÆ°á»›ng dáº«n: <https://www.youtube.com/watch?v=W99c8zVOkkg>
2. **Táº¡o mÃ´i trÆ°á»ng áº£o vÃ  cÃ i thÆ° viá»‡n**
    - Cháº¡y `02_run_train.bat` hoáº·c `03_run_test.bat` sáº½ tá»± Ä‘á»™ng táº¡o venv vÃ  cÃ i thÆ° viá»‡n tá»« `requirements.txt`
    - Náº¿u muá»‘n thá»§ cÃ´ng:

      ```bat
      python -m venv env
      env\Scripts\activate.bat
      pip install -r requirements.txt
      ```

### CÃ i Ä‘áº·t CUDA/cuDNN cho GPU

- Táº£i CUDA Toolkit táº¡i <https://developer.nvidia.com/cuda-downloads>
- Táº£i cuDNN táº¡i <https://developer.nvidia.com/cudnn>
- ThÃªm biáº¿n mÃ´i trÆ°á»ng PATH cho CUDA, cuDNN
- Kiá»ƒm tra GPU báº±ng lá»‡nh:

  ```python
  import tensorflow as tf
  print(tf.config.list_physical_devices('GPU'))
  ```

---

<a id="5-data-preparation-error-handling"></a>
## 5. CHUáº¨N Bá»Š Dá»® LIá»†U & Xá»¬ LÃ Lá»–I Dá»® LIá»†U

### Kiá»ƒm tra dá»¯ liá»‡u Ä‘Ã£ chia

1. Cháº¡y `01_setup.bat` Ä‘á»ƒ kiá»ƒm tra cÃ¡c thÆ° má»¥c train/validate/test
2. Náº¿u thiáº¿u, xem hÆ°á»›ng dáº«n táº£i vÃ  giáº£i nÃ©n táº¡i:
    [Google Drive data](https://drive.google.com/file/d/10FkuSbGvZTCURyoKs_JEbBUnFgDFL102/view?usp=sharing)

### Chia dá»¯ liá»‡u tá»± Ä‘á»™ng

1. Náº¿u cÃ³ dá»¯ liá»‡u gá»‘c á»Ÿ `kaggle/input/wikiart/`, script sáº½ tá»± Ä‘á»™ng chia báº±ng `data_collector.py` khi cháº¡y `train_model.py`
2. CÃ³ thá»ƒ cháº¡y riÃªng `data_collector.py` Ä‘á»ƒ chia láº¡i dá»¯ liá»‡u

### Xá»­ lÃ½ lá»—i dá»¯ liá»‡u

- Kiá»ƒm tra sá»‘ lÆ°á»£ng áº£nh tá»«ng class, tÃªn file, Ä‘á»‹nh dáº¡ng áº£nh (jpg, png)
- Náº¿u thiáº¿u class hoáº·c áº£nh lá»—i, script sáº½ bÃ¡o lá»—i chi tiáº¿t
- CÃ³ thá»ƒ chá»‰nh sá»­a láº¡i tÃªn class trong `constants.py` Ä‘á»ƒ phÃ¹ há»£p vá»›i dá»¯ liá»‡u thá»±c táº¿

---

<a id="6-end-user-usage-guide"></a>
## 6. HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG CHO NGÆ¯á»œI DÃ™NG CUá»I

### Huáº¥n luyá»‡n mÃ´ hÃ¬nh

1. Cháº¡y `02_run_train.bat` (tá»± Ä‘á»™ng kiá»ƒm tra Python, táº¡o venv, cÃ i thÆ° viá»‡n, huáº¥n luyá»‡n)
2. Káº¿t quáº£: mÃ´ hÃ¬nh lÆ°u táº¡i `kaggle/working/art_styles/art_style_classifier.h5`, log táº¡i `app_log/`

### Kiá»ƒm tra mÃ´ hÃ¬nh

1. Cháº¡y `03_run_test.bat` (tá»± Ä‘á»™ng kiá»ƒm tra Python, táº¡o venv, cÃ i thÆ° viá»‡n, kiá»ƒm tra mÃ´ hÃ¬nh)
2. Káº¿t quáº£: bÃ¡o cÃ¡o accuracy, loss, classification report, confusion matrix, vÃ­ dá»¥ dá»± Ä‘oÃ¡n

### Quy trÃ¬nh sá»­ dá»¥ng nhanh

```text
01_setup.bat   # Kiá»ƒm tra dá»¯ liá»‡u
02_run_train.bat   # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
03_run_test.bat    # Kiá»ƒm tra mÃ´ hÃ¬nh
```

---

<a id="7-developer-guide-extensions"></a>
## 7. HÆ¯á»šNG DáºªN CHO DEVELOPER & Má» Rá»˜NG

### Chá»‰nh sá»­a code, cáº¥u trÃºc thÆ° má»¥c, chia láº¡i dá»¯ liá»‡u

1. Sá»­a cÃ¡c biáº¿n trong `constants.py` Ä‘á»ƒ thay Ä‘á»•i Ä‘Æ°á»ng dáº«n, class, tÃªn file
2. Cháº¡y trá»±c tiáº¿p cÃ¡c file Python:

    ```bash
    python train_model.py
    python test_model.py
    ```

3. Sá»­ dá»¥ng `data_collector.py` Ä‘á»ƒ chia dá»¯ liá»‡u tá»± Ä‘á»™ng tá»« thÆ° má»¥c gá»‘c

### Má»Ÿ rá»™ng mÃ´ hÃ¬nh, thÃªm class, thay Ä‘á»•i tham sá»‘

1. Sá»­a cÃ¡c biáº¿n, hÃ m trong `train_model.py`, `test_model.py`, `constants.py`
2. CÃ³ thá»ƒ thÃªm cÃ¡c callback, layer, hoáº·c thay Ä‘á»•i thuáº­t toÃ¡n augmentation
3. TÃ­ch há»£p thÃªm cÃ¡c mÃ´ hÃ¬nh khÃ¡c (EfficientNet, ResNet, MobileNet)

### Quáº£n lÃ½ mÃ´i trÆ°á»ng, version, backup

- Sá»­ dá»¥ng venv cho tá»«ng project
- Quáº£n lÃ½ version báº±ng git, commit thÆ°á»ng xuyÃªn
- Backup dá»¯ liá»‡u, mÃ´ hÃ¬nh, log Ä‘á»‹nh ká»³

---

<a id="8-detailed-file-explanations-processing-flows"></a>
## 8. GIáº¢I THÃCH CHI TIáº¾T Tá»ªNG FILE & LUá»’NG Xá»¬ LÃ

### constants.py

File nÃ y Ä‘á»‹nh nghÄ©a táº¥t cáº£ cÃ¡c háº±ng sá»‘ vÃ  Ä‘Æ°á»ng dáº«n dÃ¹ng chung cho toÃ n bá»™ dá»± Ã¡n. Viá»‡c táº­p trung quáº£n lÃ½ nÃ y giÃºp dá»… dÃ ng thay Ä‘á»•i cáº¥u hÃ¬nh mÃ  khÃ´ng cáº§n sá»­a nhiá»u file.

```python
# constants.py
# Äá»‹nh nghÄ©a cÃ¡c háº±ng sá»‘ vÃ  Ä‘Æ°á»ng dáº«n dÃ¹ng chung cho project

DATA_BASE_DIR = 'kaggle/input'  # ThÆ° má»¥c gá»‘c chá»©a dá»¯ liá»‡u Ä‘áº§u vÃ o tá»« Kaggle
WORKING_BASE_DIR = 'kaggle/working/art_styles'  # ThÆ° má»¥c lÃ m viá»‡c chá»©a dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  chia
LOG_DIR = 'app_log'  # ThÆ° má»¥c lÆ°u trá»¯ cÃ¡c file log cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n
MODEL_FILENAME = 'art_style_classifier.h5'  # TÃªn file Ä‘á»ƒ lÆ°u mÃ´ hÃ¬nh Keras sau khi huáº¥n luyá»‡n
TFLITE_MODEL_FILENAME = 'style_model.tflite'  # TÃªn file cho mÃ´ hÃ¬nh TensorFlow Lite (dÃ nh cho triá»ƒn khai trÃªn mobile)
LABELS_FILENAME = 'labels.txt'  # TÃªn file chá»©a mapping tá»« index sang tÃªn phong cÃ¡ch

STYLE_CLASSES = [  # Danh sÃ¡ch cÃ¡c phong cÃ¡ch nghá»‡ thuáº­t Ä‘Æ°á»£c phÃ¢n loáº¡i trong mÃ´ hÃ¬nh
    'Baroque',  # Phong cÃ¡ch Baroque vá»›i Ä‘áº·c trÆ°ng vá» mÃ u sáº¯c rá»±c rá»¡ vÃ  chi tiáº¿t phá»©c táº¡p
    'Expressionism',  # Phong cÃ¡ch Expressionism táº­p trung vÃ o biá»ƒu Ä‘áº¡t cáº£m xÃºc
    'Cubism',  # Phong cÃ¡ch Cubism vá»›i hÃ¬nh dáº¡ng hÃ¬nh há»c vÃ  gÃ³c nhÃ¬n Ä‘a chiá»u
    'Japanese_Art',  # Nghá»‡ thuáº­t Nháº­t Báº£n vá»›i Ä‘áº·c trÆ°ng vá» Ä‘Æ°á»ng nÃ©t tinh táº¿ vÃ  mÃ u sáº¯c tá»± nhiÃªn
    'Art_Nouveau_Modern'  # Phong cÃ¡ch Art Nouveau hiá»‡n Ä‘áº¡i vá»›i Ä‘Æ°á»ng cong vÃ  motif tá»± nhiÃªn
]
```

Giáº£i thÃ­ch chi tiáº¿t:

- `DATA_BASE_DIR`: ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a dá»¯ liá»‡u gá»‘c. Trong mÃ´i trÆ°á»ng Kaggle, Ä‘Ã¢y lÃ  nÆ¡i chá»©a dataset táº£i vá».
- `WORKING_BASE_DIR`: ThÆ° má»¥c lÃ m viá»‡c chÃ­nh, nÆ¡i chá»©a dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh train/validate/test vÃ  lÆ°u mÃ´ hÃ¬nh.
- `LOG_DIR`: ThÆ° má»¥c lÆ°u log Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh huáº¥n luyá»‡n, giÃºp debug vÃ  monitor hiá»‡u suáº¥t.
- `MODEL_FILENAME`: TÃªn file mÃ´ hÃ¬nh Keras (.h5), Ä‘á»‹nh dáº¡ng chuáº©n cho lÆ°u trá»¯ mÃ´ hÃ¬nh TensorFlow/Keras.
- `TFLITE_MODEL_FILENAME`: Chuáº©n bá»‹ cho viá»‡c chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh sang TensorFlow Lite Ä‘á»ƒ cháº¡y trÃªn thiáº¿t bá»‹ edge.
- `LABELS_FILENAME`: File text chá»©a tÃªn cÃ¡c class theo thá»© tá»± index, cáº§n thiáº¿t cho viá»‡c inference.
- `STYLE_CLASSES`: Danh sÃ¡ch 5 phong cÃ¡ch Ä‘Æ°á»£c chá»n dá»±a trÃªn sá»± Ä‘a dáº¡ng vÃ  kháº£ nÄƒng phÃ¢n biá»‡t. CÃ³ thá»ƒ dá»… dÃ ng thÃªm hoáº·c bá»›t class báº±ng cÃ¡ch sá»­a list nÃ y.

### data_collector.py

File nÃ y chá»‹u trÃ¡ch nhiá»‡m chia dá»¯ liá»‡u tá»« thÆ° má»¥c gá»‘c thÃ nh cÃ¡c táº­p train, validate, test. Äiá»u nÃ y Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n chia ngáº«u nhiÃªn vÃ  cÃ¢n báº±ng.

```python
import os  # ThÆ° viá»‡n xá»­ lÃ½ Ä‘Æ°á»ng dáº«n vÃ  thao tÃ¡c file há»‡ thá»‘ng
import shutil  # ThÆ° viá»‡n sao chÃ©p vÃ  di chuyá»ƒn file
import logging  # ThÆ° viá»‡n ghi log Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh
from sklearn.model_selection import train_test_split  # HÃ m chia dá»¯ liá»‡u tá»« scikit-learn

def create_directories(output_base_dir, styles):  # HÃ m táº¡o cáº¥u trÃºc thÆ° má»¥c cho dá»¯ liá»‡u Ä‘Ã£ chia
    try:
        os.makedirs(output_base_dir, exist_ok=True)  # Táº¡o thÆ° má»¥c gá»‘c náº¿u chÆ°a cÃ³
        for split in ['train', 'validate', 'test']:  # Láº·p qua cÃ¡c táº­p dá»¯ liá»‡u
            os.makedirs(os.path.join(output_base_dir, split), exist_ok=True)  # Táº¡o thÆ° má»¥c cho tá»«ng táº­p
            for style in styles:  # Láº·p qua cÃ¡c phong cÃ¡ch
                os.makedirs(os.path.join(output_base_dir, split, style), exist_ok=True)  # Táº¡o thÆ° má»¥c con cho tá»«ng phong cÃ¡ch
        print("ThÆ° má»¥c Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng.")  # ThÃ´ng bÃ¡o thÃ nh cÃ´ng
    except OSError as e:  # Báº¯t lá»—i náº¿u táº¡o thÆ° má»¥c tháº¥t báº¡i
        print(f"Lá»—i khi táº¡o thÆ° má»¥c: {e}")  # In lá»—i

def split_data(main_dir, training_dir, validation_dir, test_dir, split_size, max_files=2000, random_seed=42):  # HÃ m chia dá»¯ liá»‡u
    if not main_dir or not os.path.exists(main_dir):  # Kiá»ƒm tra thÆ° má»¥c nguá»“n cÃ³ tá»“n táº¡i
        logging.error("Lá»—i: main_dir khÃ´ng há»£p lá»‡ hoáº·c khÃ´ng tá»“n táº¡i.")  # Ghi log lá»—i
        return  # ThoÃ¡t hÃ m
    if not (0 < split_size < 1):  # Kiá»ƒm tra tá»· lá»‡ chia há»£p lá»‡
        logging.error("Lá»—i: split_size pháº£i náº±m giá»¯a 0 vÃ  1.")  # Ghi log lá»—i
        return  # ThoÃ¡t hÃ m
    os.makedirs(training_dir, exist_ok=True)  # Táº¡o thÆ° má»¥c train
    os.makedirs(validation_dir, exist_ok=True)  # Táº¡o thÆ° má»¥c validate
    os.makedirs(test_dir, exist_ok=True)  # Táº¡o thÆ° má»¥c test
    all_files = [file for file in os.listdir(main_dir) if os.path.isfile(os.path.join(main_dir, file)) and os.path.getsize(os.path.join(main_dir, file)) > 0]  # Láº¥y danh sÃ¡ch file áº£nh há»£p lá»‡
    if not all_files:  # Náº¿u khÃ´ng cÃ³ file nÃ o
        logging.error("Lá»—i: main_dir trá»‘ng.")  # Ghi log lá»—i
        return  # ThoÃ¡t hÃ m
    if len(all_files) > max_files:  # Giá»›i háº¡n sá»‘ lÆ°á»£ng file Ä‘á»ƒ cÃ¢n báº±ng
        all_files = all_files[:max_files]  # Cáº¯t bá»›t file
        logging.info(f"Giá»›i háº¡n {max_files} tá»‡p tá»« tá»•ng sá»‘ {len(all_files)}.")  # Ghi log thÃ´ng tin
    train_files, remaining_files = train_test_split(all_files, train_size=split_size, random_state=random_seed)  # Chia thÃ nh train vÃ  remaining
    validation_files, test_files = train_test_split(remaining_files, test_size=0.5, random_state=random_seed)  # Chia remaining thÃ nh validate vÃ  test
    def copy_files(source_dir, destination_dir, file_list):  # HÃ m phá»¥ Ä‘á»ƒ sao chÃ©p file
        for file in file_list:  # Láº·p qua danh sÃ¡ch file
            src_path = os.path.join(source_dir, file)  # ÄÆ°á»ng dáº«n nguá»“n
            dst_path = os.path.join(destination_dir, file)  # ÄÆ°á»ng dáº«n Ä‘Ã­ch
            if not os.path.isfile(src_path):  # Kiá»ƒm tra file tá»“n táº¡i
                logging.warning(f"Bá» qua khÃ´ng pháº£i file: {file}")  # Cáº£nh bÃ¡o
                continue  # Bá» qua
            try:
                shutil.copyfile(src_path, dst_path)  # Sao chÃ©p file
            except Exception as e:  # Báº¯t lá»—i sao chÃ©p
                logging.error(f"Lá»—i sao chÃ©p {file}: {e}")  # Ghi log lá»—i
    copy_files(main_dir, training_dir, train_files)  # Sao chÃ©p file train
    copy_files(main_dir, validation_dir, validation_files)  # Sao chÃ©p file validate
    copy_files(main_dir, test_dir, test_files)  # Sao chÃ©p file test
    logging.info("Chia dá»¯ liá»‡u thÃ nh cÃ´ng!")  # ThÃ´ng bÃ¡o thÃ nh cÃ´ng

def collect_data_if_needed(output_base_dir, style_dirs, styles):  # HÃ m chÃ­nh kiá»ƒm tra vÃ  chia dá»¯ liá»‡u náº¿u cáº§n
    # Kiá»ƒm tra náº¿u cÃ¡c thÆ° má»¥c train/validate/test Ä‘Ã£ cÃ³ dá»¯ liá»‡u thÃ¬ bá» qua
    train_dir = os.path.join(output_base_dir, 'train')  # ÄÆ°á»ng dáº«n thÆ° má»¥c train
    validate_dir = os.path.join(output_base_dir, 'validate')  # ÄÆ°á»ng dáº«n thÆ° má»¥c validate
    test_dir = os.path.join(output_base_dir, 'test')  # ÄÆ°á»ng dáº«n thÆ° má»¥c test
    need_collect = False  # Cá» kiá»ƒm tra cÃ³ cáº§n chia dá»¯ liá»‡u
    for split_dir in [train_dir, validate_dir, test_dir]:  # Kiá»ƒm tra tá»«ng thÆ° má»¥c
        if not os.path.exists(split_dir) or not any(os.listdir(split_dir)):  # Náº¿u thÆ° má»¥c khÃ´ng tá»“n táº¡i hoáº·c rá»—ng
            need_collect = True  # Äáº·t cá» cáº§n chia
    if not need_collect:  # Náº¿u khÃ´ng cáº§n chia
        print("Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia, khÃ´ng cáº§n collect láº¡i.")  # ThÃ´ng bÃ¡o
        return  # ThoÃ¡t hÃ m
    create_directories(output_base_dir, styles)  # Táº¡o cáº¥u trÃºc thÆ° má»¥c
    for style, style_dir in style_dirs.items():  # Láº·p qua tá»«ng phong cÃ¡ch
        split_data(  # Gá»i hÃ m chia dá»¯ liá»‡u
            style_dir,  # ThÆ° má»¥c nguá»“n cá»§a phong cÃ¡ch
            os.path.join(output_base_dir, f"train/{style}"),  # ThÆ° má»¥c Ä‘Ã­ch train
            os.path.join(output_base_dir, f"validate/{style}"),  # ThÆ° má»¥c Ä‘Ã­ch validate
            os.path.join(output_base_dir, f"test/{style}"),  # ThÆ° má»¥c Ä‘Ã­ch test
            0.8  # Tá»· lá»‡ train 80%
        )
```

Giáº£i thÃ­ch chi tiáº¿t:

- HÃ m `create_directories`: Táº¡o cáº¥u trÃºc thÆ° má»¥c phÃ¢n cáº¥p cho train/validate/test vÃ  tá»«ng phong cÃ¡ch. Sá»­ dá»¥ng `exist_ok=True` Ä‘á»ƒ trÃ¡nh lá»—i náº¿u thÆ° má»¥c Ä‘Ã£ tá»“n táº¡i.
- HÃ m `split_data`: Thá»±c hiá»‡n chia dá»¯ liá»‡u vá»›i kiá»ƒm tra lá»—i toÃ n diá»‡n. Sá»­ dá»¥ng `train_test_split` tá»« sklearn Ä‘á»ƒ chia ngáº«u nhiÃªn nhÆ°ng cÃ³ thá»ƒ tÃ¡i táº¡o (random_seed). Giá»›i háº¡n max_files Ä‘á»ƒ cÃ¢n báº±ng sá»‘ lÆ°á»£ng áº£nh giá»¯a cÃ¡c class.
- HÃ m `copy_files`: HÃ m phá»¥ an toÃ n Ä‘á»ƒ sao chÃ©p file, vá»›i xá»­ lÃ½ lá»—i chi tiáº¿t.
- HÃ m `collect_data_if_needed`: HÃ m chÃ­nh kiá»ƒm tra xem Ä‘Ã£ cÃ³ dá»¯ liá»‡u chia chÆ°a, náº¿u chÆ°a thÃ¬ tá»± Ä‘á»™ng chia. Äiá»u nÃ y trÃ¡nh cháº¡y láº¡i khÃ´ng cáº§n thiáº¿t.

### train_model.py

File nÃ y lÃ  script chÃ­nh Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. NÃ³ bao gá»“m viá»‡c chuáº©n bá»‹ dá»¯ liá»‡u, xÃ¢y dá»±ng mÃ´ hÃ¬nh, huáº¥n luyá»‡n 2 giai Ä‘oáº¡n vÃ  lÆ°u káº¿t quáº£.

```python
#!/usr/bin/env python  # Shebang Ä‘á»ƒ cháº¡y script trá»±c tiáº¿p
# -*- coding: utf-8 -*-  # Encoding UTF-8 cho tiáº¿ng Viá»‡t
"""
Script Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i phong cÃ¡ch nghá»‡ thuáº­t.
Dá»±a trÃªn notebook gá»‘c, tÃ¡ch riÃªng pháº§n training.
"""

import numpy as np  # ThÆ° viá»‡n tÃ­nh toÃ¡n sá»‘ há»c
import pandas as pd  # ThÆ° viá»‡n xá»­ lÃ½ dá»¯ liá»‡u (máº·c dÃ¹ khÃ´ng dÃ¹ng nhiá»u á»Ÿ Ä‘Ã¢y)
import os  # Xá»­ lÃ½ Ä‘Æ°á»ng dáº«n
import shutil  # Sao chÃ©p file (khÃ´ng dÃ¹ng trá»±c tiáº¿p)
from sklearn.model_selection import train_test_split  # Chia dá»¯ liá»‡u (khÃ´ng dÃ¹ng trá»±c tiáº¿p)
import logging  # Ghi log
from tensorflow.python.client import device_lib  # Kiá»ƒm tra thiáº¿t bá»‹ TensorFlow

print("Danh sÃ¡ch thiáº¿t bá»‹ TensorFlow nháº­n diá»‡n:")  # In danh sÃ¡ch thiáº¿t bá»‹
for device in device_lib.list_local_devices():  # Láº·p qua thiáº¿t bá»‹
    print(device)  # In thÃ´ng tin thiáº¿t bá»‹
import sys  # Xá»­ lÃ½ system
from datetime import datetime  # Xá»­ lÃ½ thá»i gian
from constants import DATA_BASE_DIR, WORKING_BASE_DIR, LOG_DIR, MODEL_FILENAME, STYLE_CLASSES  # Import háº±ng sá»‘

# Import cÃ¡c thÆ° viá»‡n Keras/TensorFlow
from tensorflow.keras.models import Sequential  # MÃ´ hÃ¬nh tuáº§n tá»±
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization  # CÃ¡c lá»›p layer
from tensorflow.keras.utils import to_categorical  # One-hot encoding (khÃ´ng dÃ¹ng)
from tensorflow.keras.optimizers import SGD  # Optimizer SGD (khÃ´ng dÃ¹ng)
import matplotlib.pyplot as plt  # Váº½ biá»ƒu Ä‘á»“ (khÃ´ng dÃ¹ng trá»±c tiáº¿p)
import keras  # Keras
from tensorflow.keras.applications.vgg16 import VGG16  # MÃ´ hÃ¬nh VGG16 (khÃ´ng dÃ¹ng)
import keras_tuner as kt  # Keras Tuner (khÃ´ng dÃ¹ng)
from tensorflow.keras.applications import ResNet50, InceptionV3, DenseNet121, Xception, EfficientNetB1  # CÃ¡c mÃ´ hÃ¬nh pre-trained
from tensorflow.keras import layers, models, optimizers  # CÃ¡c module Keras
from tensorflow.keras.regularizers import l2  # Regularizer L2 (khÃ´ng dÃ¹ng)
from sklearn.model_selection import train_test_split  # (duplicate import)
from sklearn.metrics import confusion_matrix, classification_report  # ÄÃ¡nh giÃ¡ (khÃ´ng dÃ¹ng trá»±c tiáº¿p)
from tensorflow.keras.metrics import Precision, Recall, F1Score  # Metrics (khÃ´ng dÃ¹ng)
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Generator áº£nh
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping  # Callbacks
import matplotlib.pyplot as plt  # (duplicate)
import seaborn as sns  # Váº½ heatmap (khÃ´ng dÃ¹ng)
import numpy as np  # (duplicate)
from tensorflow.keras.preprocessing import image  # Xá»­ lÃ½ áº£nh (khÃ´ng dÃ¹ng)
import os  # (duplicate)
from glob import glob  # TÃ¬m file (khÃ´ng dÃ¹ng)
import shutil  # (duplicate)
import random  # Random (khÃ´ng dÃ¹ng)
from shutil import copyfile  # Sao chÃ©p file (khÃ´ng dÃ¹ng)

# Táº¡o tÃªn file log theo thá»i gian
os.makedirs(LOG_DIR, exist_ok=True)  # Táº¡o thÆ° má»¥c log náº¿u chÆ°a cÃ³
session_time = datetime.now().strftime('%Y%m%d_%H%M%S')  # Táº¡o timestamp
log_file = os.path.join(LOG_DIR, f'session_{session_time}.txt')  # ÄÆ°á»ng dáº«n file log

# Cáº¥u hÃ¬nh logging ra file
logging.basicConfig(  # Cáº¥u hÃ¬nh logging
    level=logging.INFO,  # Má»©c Ä‘á»™ INFO
    format='%(asctime)s - %(levelname)s - %(message)s',  # Format log
    handlers=[  # Handlers
        logging.FileHandler(log_file, encoding='utf-8'),  # Ghi ra file
        logging.StreamHandler(sys.stdout)  # In ra console
    ]
)

# Ghi láº¡i cÃ¡c print ra file log
class LoggerWriter:  # Class Ä‘á»ƒ redirect stdout/stderr
    def __init__(self, logger, level):  # Khá»Ÿi táº¡o
        self.logger = logger  # Logger object
        self.level = level  # Má»©c Ä‘á»™
    def write(self, message):  # PhÆ°Æ¡ng thá»©c write
        message = message.strip()  # Loáº¡i bá» khoáº£ng tráº¯ng
        if message:  # Náº¿u cÃ³ message
            self.logger.log(self.level, message)  # Ghi log
    def flush(self):  # PhÆ°Æ¡ng thá»©c flush
        pass  # KhÃ´ng lÃ m gÃ¬
sys.stdout = LoggerWriter(logging.getLogger(), logging.INFO)  # Redirect stdout
sys.stderr = LoggerWriter(logging.getLogger(), logging.ERROR)  # Redirect stderr

OUTPUT_BASE_DIR = WORKING_BASE_DIR  # Äáº·t thÆ° má»¥c output

try:  # Thá»­ import data_collector
    from data_collector import collect_data_if_needed  # Import hÃ m chia dá»¯ liá»‡u
    style_dirs = {style: os.path.join(DATA_BASE_DIR, f'wikiart/{style}') for style in STYLE_CLASSES}  # Táº¡o dict Ä‘Æ°á»ng dáº«n
    collect_data_if_needed(OUTPUT_BASE_DIR, style_dirs, STYLE_CLASSES)  # Gá»i hÃ m chia dá»¯ liá»‡u náº¿u cáº§n
except ImportError:  # Náº¿u khÃ´ng tÃ¬m tháº¥y
    print("KhÃ´ng tÃ¬m tháº¥y data_collector, chá»‰ sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã£ chia sáºµn.")  # ThÃ´ng bÃ¡o

# Táº¡o train generator vá»›i augmentation
train_gen = ImageDataGenerator(  # Generator cho train
    rescale=1./255.,  # Rescale vá» [0,1]
    width_shift_range=0.1,  # Shift ngang 10%
    height_shift_range=0.1,  # Shift dá»c 10%
    fill_mode='nearest'  # Äiá»n pixel gáº§n nháº¥t
)

validation_gen = ImageDataGenerator(rescale=1./255.)  # Generator cho validation, chá»‰ rescale

# Táº¡o train generator
train_generator = train_gen.flow_from_directory(  # Táº¡o generator tá»« thÆ° má»¥c
    os.path.join(OUTPUT_BASE_DIR, 'train'),  # ÄÆ°á»ng dáº«n thÆ° má»¥c train
    target_size=(256, 256),  # Resize vá» 256x256
    batch_size=64,  # Batch size 64
    class_mode="categorical"  # Classification Ä‘a lá»›p
)

# Táº¡o validation generator
validation_generator = validation_gen.flow_from_directory(  # Táº¡o generator tá»« thÆ° má»¥c
    os.path.join(OUTPUT_BASE_DIR, 'validate'),  # ÄÆ°á»ng dáº«n thÆ° má»¥c validate
    target_size=(256, 256),  # Resize vá» 256x256
    batch_size=64,  # Batch size 64
    class_mode="categorical"  # Classification Ä‘a lá»›p
)

# XÃ¢y dá»±ng mÃ´ hÃ¬nh
base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256, 3))  # Load Xception pre-trained
for layer in base_model.layers:  # Freeze táº¥t cáº£ layers cá»§a base model
    layer.trainable = False

model = Sequential()  # Táº¡o mÃ´ hÃ¬nh tuáº§n tá»±
model.add(base_model)  # ThÃªm base model
model.add(GlobalAveragePooling2D())  # ThÃªm GAP layer
model.add(Dense(1024, activation='relu'))  # Dense layer 1024 neurons
model.add(BatchNormalization())  # Batch norm
model.add(Dropout(0.2))  # Dropout 20%
model.add(Dense(5, activation='softmax'))  # Output layer 5 classes

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Compile mÃ´ hÃ¬nh
print("TÃ³m táº¯t mÃ´ hÃ¬nh ban Ä‘áº§u:")  # In summary
model.summary()  # Hiá»ƒn thá»‹ cáº¥u trÃºc mÃ´ hÃ¬nh

# Callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Early stopping
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)  # Reduce LR

# Huáº¥n luyá»‡n giai Ä‘oáº¡n 1
print("Báº¯t Ä‘áº§u huáº¥n luyá»‡n giai Ä‘oáº¡n 1...")  # ThÃ´ng bÃ¡o
result1 = model.fit(  # Fit mÃ´ hÃ¬nh
    train_generator,  # Train generator
    epochs=10,  # 10 epochs
    validation_data=validation_generator  # Validation generator
)

# Má»Ÿ khÃ³a má»™t sá»‘ lá»›p cuá»‘i
for layer in base_model.layers[-35:]:  # Unfreeze 35 layers cuá»‘i
    layer.trainable = True

# BiÃªn dá»‹ch láº¡i vá»›i learning rate tháº¥p hÆ¡n
model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])  # Recompile vá»›i LR tháº¥p
print("TÃ³m táº¯t mÃ´ hÃ¬nh sau khi fine-tune:")  # In summary
model.summary()  # Hiá»ƒn thá»‹ cáº¥u trÃºc

# Huáº¥n luyá»‡n giai Ä‘oáº¡n 2
print("Báº¯t Ä‘áº§u huáº¥n luyá»‡n giai Ä‘oáº¡n 2 (fine-tuning)...")  # ThÃ´ng bÃ¡o
result2 = model.fit(  # Fit láº¡i
    train_generator,  # Train generator
    epochs=50,  # 50 epochs
    callbacks=[reduce_lr, early_stop],  # Callbacks
    validation_data=validation_generator  # Validation generator
)

# LÆ°u mÃ´ hÃ¬nh
model.save(os.path.join(OUTPUT_BASE_DIR, MODEL_FILENAME))  # LÆ°u mÃ´ hÃ¬nh
print(f"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i {os.path.join(OUTPUT_BASE_DIR, MODEL_FILENAME)}")  # ThÃ´ng bÃ¡o
```

Giáº£i thÃ­ch chi tiáº¿t:

- Pháº§n import: Nhiá»u import khÃ´ng dÃ¹ng do copy tá»« notebook, nhÆ°ng giá»¯ láº¡i Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch.
- Logging setup: Táº¡o file log theo timestamp, redirect stdout/stderr Ä‘á»ƒ ghi log.
- Data collection: Tá»± Ä‘á»™ng chia dá»¯ liá»‡u náº¿u cáº§n.
- Generators: Táº¡o ImageDataGenerator cho train (vá»›i augmentation) vÃ  validation.
- Model building: Sá»­ dá»¥ng Xception pre-trained, thÃªm cÃ¡c layer custom, compile vá»›i Adam.
- Training phase 1: Freeze base model, train top layers.
- Fine-tuning: Unfreeze má»™t sá»‘ layers cuá»‘i, train vá»›i LR tháº¥p hÆ¡n.
- Callbacks: Early stopping vÃ  reduce LR Ä‘á»ƒ trÃ¡nh overfitting.
- Save model: LÆ°u mÃ´ hÃ¬nh sau khi train xong.

### test_model.py

File nÃ y dÃ¹ng Ä‘á»ƒ kiá»ƒm tra vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n, xuáº¥t bÃ¡o cÃ¡o vÃ  visualization.

```python
#!/usr/bin/env python  # Shebang
# -*- coding: utf-8 -*-  # Encoding
"""
Script Ä‘á»ƒ kiá»ƒm tra vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh phÃ¢n loáº¡i phong cÃ¡ch nghá»‡ thuáº­t.
Dá»±a trÃªn notebook gá»‘c, tÃ¡ch riÃªng pháº§n testing.
"""

import os  # Xá»­ lÃ½ Ä‘Æ°á»ng dáº«n
import random  # Random Ä‘á»ƒ chá»n áº£nh máº«u
import numpy as np  # TÃ­nh toÃ¡n
import matplotlib.pyplot as plt  # Váº½ biá»ƒu Ä‘á»“
import seaborn as sns  # Váº½ heatmap
from sklearn.metrics import confusion_matrix, classification_report  # Metrics
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Generator
from tensorflow.keras.models import load_model  # Load mÃ´ hÃ¬nh
from tensorflow.keras.preprocessing import image  # Xá»­ lÃ½ áº£nh
import tensorflow as tf  # TensorFlow
from constants import WORKING_BASE_DIR, MODEL_FILENAME, LABELS_FILENAME  # Import constants

# Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n
OUTPUT_BASE_DIR = WORKING_BASE_DIR  # ThÆ° má»¥c output
MODEL_PATH = os.path.join(OUTPUT_BASE_DIR, MODEL_FILENAME)  # ÄÆ°á»ng dáº«n mÃ´ hÃ¬nh
LABELS_PATH = LABELS_FILENAME  # ÄÆ°á»ng dáº«n labels

# Táº£i mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
print("Äang táº£i mÃ´ hÃ¬nh...")  # ThÃ´ng bÃ¡o
model = load_model(MODEL_PATH)  # Load mÃ´ hÃ¬nh
print("MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng.")  # ThÃ´ng bÃ¡o

# Táº¡o test generator
test_gen = ImageDataGenerator(rescale=1./255.)  # Generator cho test, chá»‰ rescale

test_generator = test_gen.flow_from_directory(  # Táº¡o generator tá»« thÆ° má»¥c test
    os.path.join(OUTPUT_BASE_DIR, 'test'),  # ÄÆ°á»ng dáº«n thÆ° má»¥c test
    target_size=(256, 256),  # Resize 256x256
    batch_size=64,  # Batch size 64
    shuffle=False,  # KhÃ´ng shuffle Ä‘á»ƒ giá»¯ thá»© tá»±
    class_mode="categorical"  # Categorical classification
)

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation (Ä‘á»ƒ so sÃ¡nh)
validation_gen = ImageDataGenerator(rescale=1./255.)  # Generator cho validation
validation_generator = validation_gen.flow_from_directory(  # Táº¡o generator
    os.path.join(OUTPUT_BASE_DIR, 'validate'),  # ÄÆ°á»ng dáº«n validate
    target_size=(256, 256),  # Resize
    batch_size=64,  # Batch size
    shuffle=False,  # KhÃ´ng shuffle
    class_mode="categorical"  # Categorical
)

print("ÄÃ¡nh giÃ¡ trÃªn táº­p validation:")  # ThÃ´ng bÃ¡o
loss, accuracy = model.evaluate(validation_generator)  # Evaluate trÃªn validation
print(f"Äá»™ chÃ­nh xÃ¡c: {accuracy:.4f}")  # In accuracy
print(f"Máº¥t mÃ¡t: {loss:.4f}")  # In loss

# Dá»± Ä‘oÃ¡n trÃªn táº­p test
print("Äang dá»± Ä‘oÃ¡n trÃªn táº­p test...")  # ThÃ´ng bÃ¡o
y_pred_prob = model.predict(test_generator)  # Predict probabilities
y_pred = np.argmax(y_pred_prob, axis=1)  # Láº¥y class vá»›i prob cao nháº¥t
y_true = test_generator.classes  # True labels

# BÃ¡o cÃ¡o phÃ¢n loáº¡i
class_labels = list(test_generator.class_indices.keys())  # Láº¥y tÃªn classes
report = classification_report(y_true, y_pred, target_names=class_labels)  # Táº¡o report
print("BÃ¡o cÃ¡o phÃ¢n loáº¡i:")  # ThÃ´ng bÃ¡o
print(report)  # In report

# Ma tráº­n nháº§m láº«n
conf_matrix = confusion_matrix(y_true, y_pred)  # Táº¡o confusion matrix
plt.figure(figsize=(8, 6))  # Táº¡o figure
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)  # Váº½ heatmap
plt.xlabel('NhÃ£n dá»± Ä‘oÃ¡n')  # Label x
plt.ylabel('NhÃ£n thá»±c táº¿')  # Label y
plt.title('Ma tráº­n nháº§m láº«n')  # Title
plt.show()  # Hiá»ƒn thá»‹

# HÃ m hiá»ƒn thá»‹ lÆ°á»›i áº£nh vá»›i dá»± Ä‘oÃ¡n
def display_image_grid(model, n=9, num_cols=3):  # HÃ m hiá»ƒn thá»‹ áº£nh máº«u
    """
    Hiá»ƒn thá»‹ lÆ°á»›i áº£nh vá»›i phong cÃ¡ch thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n.

    Tham sá»‘:
    model (tf.keras.Model): MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ dá»± Ä‘oÃ¡n phong cÃ¡ch áº£nh.
    n (int): Sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ hiá»ƒn thá»‹. Máº·c Ä‘á»‹nh lÃ  9.
    num_cols (int): Sá»‘ cá»™t trong lÆ°á»›i. Máº·c Ä‘á»‹nh lÃ  3.
    """
    num_rows = (n + num_cols - 1) // num_cols  # TÃ­nh sá»‘ hÃ ng

    test_images_dir = os.path.join(OUTPUT_BASE_DIR, 'test')  # ÄÆ°á»ng dáº«n thÆ° má»¥c test

    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))  # Táº¡o subplot

    for i in range(n):  # Láº·p qua n áº£nh
        row = i // num_cols  # TÃ­nh hÃ ng
        col = i % num_cols  # TÃ­nh cá»™t

        # Chá»n ngáº«u nhiÃªn má»™t phong cÃ¡ch vÃ  má»™t áº£nh trong phong cÃ¡ch Ä‘Ã³
        random_style = random.choice(os.listdir(test_images_dir))  # Chá»n style ngáº«u nhiÃªn
        random_image = random.choice(os.listdir(os.path.join(test_images_dir, random_style)))  # Chá»n áº£nh ngáº«u nhiÃªn
        random_image_file = os.path.join(test_images_dir, random_style, random_image)  # ÄÆ°á»ng dáº«n file

        # Táº£i vÃ  tiá»n xá»­ lÃ½ áº£nh
        test_image = image.load_img(random_image_file, target_size=(256, 256))  # Load vÃ  resize
        test_image_array = image.img_to_array(test_image) / 255.  # Chuyá»ƒn array vÃ  rescale
        test_image_array = np.expand_dims(test_image_array, axis=0)  # ThÃªm batch dimension

        # Dá»± Ä‘oÃ¡n phong cÃ¡ch nghá»‡ thuáº­t
        prediction = model.predict(test_image_array)  # Predict
        prediction_probability = np.amax(prediction)  # Prob cao nháº¥t
        prediction_idx = np.argmax(prediction)  # Index cá»§a class

        # Láº¥y nhÃ£n tá»« generator
        labels = {v: k for k, v in test_generator.class_indices.items()}  # Dict index -> name

        # Kiá»ƒm tra xem dá»± Ä‘oÃ¡n cÃ³ Ä‘Ãºng khÃ´ng
        actual_style = random_style.replace('_', ' ')  # Thay '_' thÃ nh space
        predicted_style = labels[prediction_idx].replace('_', ' ')  # Thay '_' thÃ nh space
        is_correct = actual_style == predicted_style  # Kiá»ƒm tra Ä‘Ãºng
        title_color = 'green' if is_correct else 'red'  # MÃ u title

        # Táº¡o tiÃªu Ä‘á» vá»›i phong cÃ¡ch thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n
        title = f"Phong cÃ¡ch thá»±c táº¿ = {actual_style}\n" \
                f"Phong cÃ¡ch dá»± Ä‘oÃ¡n = {predicted_style}\n" \
                f"XÃ¡c suáº¥t dá»± Ä‘oÃ¡n = {prediction_probability * 100:.2f}%"  # Táº¡o title

        # Hiá»ƒn thá»‹ áº£nh vá»›i tiÃªu Ä‘á»
        if num_rows > 1:  # Náº¿u nhiá»u hÃ ng
            ax = axes[row, col]  # Láº¥y axis
        else:  # Náº¿u 1 hÃ ng
            ax = axes[col]  # Láº¥y axis
        ax.imshow(plt.imread(random_image_file))  # Hiá»ƒn thá»‹ áº£nh
        ax.set_title(title, color=title_color, fontsize=8)  # Set title
        ax.axis('off')  # Táº¯t axis

    plt.tight_layout()  # Tight layout
    plt.show()  # Hiá»ƒn thá»‹

# Hiá»ƒn thá»‹ vÃ­ dá»¥ dá»± Ä‘oÃ¡n
print("Hiá»ƒn thá»‹ vÃ­ dá»¥ dá»± Ä‘oÃ¡n trÃªn 4 áº£nh:")  # ThÃ´ng bÃ¡o
display_image_grid(model, n=4, num_cols=2)  # Gá»i hÃ m vá»›i 4 áº£nh, 2 cá»™t

print("HoÃ n thÃ nh kiá»ƒm tra mÃ´ hÃ¬nh!")  # ThÃ´ng bÃ¡o hoÃ n thÃ nh
```

Giáº£i thÃ­ch chi tiáº¿t:

- Load model: Táº£i mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n tá»« file.
- Generators: Táº¡o generator cho test vÃ  validation, khÃ´ng shuffle Ä‘á»ƒ giá»¯ thá»© tá»±.
- Evaluation: ÄÃ¡nh giÃ¡ trÃªn validation Ä‘á»ƒ so sÃ¡nh.
- Prediction: Dá»± Ä‘oÃ¡n trÃªn test, tÃ­nh metrics.
- Classification report: BÃ¡o cÃ¡o precision, recall, f1-score cho tá»«ng class.
- Confusion matrix: Ma tráº­n hiá»ƒn thá»‹ lá»—i phÃ¢n loáº¡i, váº½ heatmap.
- Display function: HÃ m hiá»ƒn thá»‹ áº£nh máº«u vá»›i dá»± Ä‘oÃ¡n, mÃ u xanh náº¿u Ä‘Ãºng, Ä‘á» náº¿u sai.

### 01_setup.bat

File batch Ä‘á»ƒ kiá»ƒm tra dá»¯ liá»‡u vÃ  hÆ°á»›ng dáº«n táº£i náº¿u thiáº¿u.

```bat
@echo off  # Táº¯t echo
setlocal  # Local scope

REM Kiá»ƒm tra thÆ° má»¥c dá»¯ liá»‡u Ä‘Ã£ chia
if exist "kaggle\working\art_styles\train" if exist "kaggle\working\art_styles\validate" if exist "kaggle\working\art_styles\test" (  # Náº¿u cáº£ 3 thÆ° má»¥c tá»“n táº¡i
    echo Da co du lieu train/validate/test. Tiep tuc setup...  # ThÃ´ng bÃ¡o cÃ³ dá»¯ liá»‡u
    echo Setup thanh cong. Nhan phim bat ky de thoat.  # ThÃ´ng bÃ¡o thÃ nh cÃ´ng
    pause  # Chá» nháº¥n phÃ­m
    exit /b 0  # ThoÃ¡t thÃ nh cÃ´ng
) else (  # Náº¿u thiáº¿u
    echo Chua co du lieu train/validate/test hoac thieu thu muc.  # ThÃ´ng bÃ¡o thiáº¿u
    echo Vui long xem huong dan tai va giai nen du lieu tai:  # HÆ°á»›ng dáº«n táº£i
    echo https://drive.google.com/file/d/10FkuSbGvZTCURyoKs_JEbBUnFgDFL102/view?usp=sharing  # Link táº£i
    echo Sau khi tai xong, giai nen vao dung thu muc kaggle\working\art_styles theo dung cau truc.  # HÆ°á»›ng dáº«n giáº£i nÃ©n
    pause  # Chá» nháº¥n phÃ­m
    exit /b 1  # ThoÃ¡t vá»›i lá»—i
)
endlocal  # Káº¿t thÃºc local scope
```

Giáº£i thÃ­ch chi tiáº¿t:

- Kiá»ƒm tra sá»± tá»“n táº¡i cá»§a cÃ¡c thÆ° má»¥c train/validate/test.
- Náº¿u cÃ³, thÃ´ng bÃ¡o setup thÃ nh cÃ´ng.
- Náº¿u thiáº¿u, hÆ°á»›ng dáº«n táº£i dá»¯ liá»‡u tá»« Google Drive vÃ  giáº£i nÃ©n Ä‘Ãºng cáº¥u trÃºc.

### 02_run_train.bat

File batch tá»± Ä‘á»™ng huáº¥n luyá»‡n mÃ´ hÃ¬nh.

```bat
@echo off  # Táº¯t echo
setlocal  # Local scope
REM Kiem tra Python
python --version >nul 2>&1  # Kiá»ƒm tra Python, redirect output
if errorlevel 1 (  # Náº¿u khÃ´ng tÃ¬m tháº¥y
    echo Khong tim thay Python. Vui long cai Python theo huong dan video sau:  # ThÃ´ng bÃ¡o lá»—i
    echo https://www.youtube.com/watch?v=W99c8zVOkkg  # Link video
    pause  # Chá» nháº¥n
    exit /b 1  # ThoÃ¡t lá»—i
)
REM Tao venv neu chua co
if not exist "env" (  # Náº¿u chÆ°a cÃ³ venv
    echo Tao moi virtual environment...  # ThÃ´ng bÃ¡o
    python -m venv env  # Táº¡o venv
)
REM Kich hoat venv
call env\Scripts\activate.bat  # Activate venv
REM Cai cac thu vien can thiet
if exist "requirements.txt" (  # Náº¿u cÃ³ requirements.txt
    echo Dang cai cac thu vien tu requirements.txt ...  # ThÃ´ng bÃ¡o
    pip install -r requirements.txt  # CÃ i thÆ° viá»‡n
) else (  # Náº¿u khÃ´ng cÃ³
    echo Khong tim thay requirements.txt  # ThÃ´ng bÃ¡o lá»—i
)
REM Kiem tra file train_model.py
if not exist "train_model.py" (  # Náº¿u khÃ´ng cÃ³ file
    echo Khong tim thay file train_model.py  # ThÃ´ng bÃ¡o lá»—i
    pause  # Chá» nháº¥n
    exit /b 1  # ThoÃ¡t lá»—i
)
REM Chay train_model.py
python train_model.py  # Cháº¡y script train
echo Hoan thanh train. Nhan phim bat ky de thoat.  # ThÃ´ng bÃ¡o hoÃ n thÃ nh
pause  # Chá» nháº¥n
endlocal  # Káº¿t thÃºc local scope
```

Giáº£i thÃ­ch chi tiáº¿t:

- Kiá»ƒm tra Python cÃ³ cÃ i Ä‘áº·t khÃ´ng.
- Táº¡o virtual environment náº¿u chÆ°a cÃ³.
- Activate venv vÃ  cÃ i thÆ° viá»‡n tá»« requirements.txt.
- Kiá»ƒm tra file train_model.py tá»“n táº¡i.
- Cháº¡y script huáº¥n luyá»‡n.

### 03_run_test.bat

File batch tá»± Ä‘á»™ng kiá»ƒm tra mÃ´ hÃ¬nh.

```bat
@echo off  # Táº¯t echo
setlocal  # Local scope
REM Kiem tra Python
python --version >nul 2>&1  # Kiá»ƒm tra Python
if errorlevel 1 (  # Náº¿u khÃ´ng cÃ³
    echo Khong tim thay Python. Vui long cai Python theo huong dan video sau:  # ThÃ´ng bÃ¡o
    echo https://www.youtube.com/watch?v=W99c8zVOkkg  # Link
    pause  # Chá»
    exit /b 1  # ThoÃ¡t lá»—i
)
REM Tao venv neu chua co
if not exist "env" (  # Náº¿u chÆ°a cÃ³ venv
    echo Tao moi virtual environment...  # ThÃ´ng bÃ¡o
    python -m venv env  # Táº¡o venv
)
REM Kich hoat venv
call env\Scripts\activate.bat  # Activate
REM Cai cac thu vien can thiet
if exist "requirements.txt" (  # Náº¿u cÃ³ requirements
    echo Dang cai cac thu vien tu requirements.txt ...  # ThÃ´ng bÃ¡o
    pip install -r requirements.txt  # CÃ i
) else (  # Náº¿u khÃ´ng
    echo Khong tim thay requirements.txt  # Lá»—i
)
REM Kiem tra file test_model.py
if not exist "test_model.py" (  # Náº¿u khÃ´ng cÃ³ file
    echo Khong tim thay file test_model.py  # Lá»—i
    pause  # Chá»
    exit /b 1  # ThoÃ¡t lá»—i
)
REM Chay test_model.py
python test_model.py  # Cháº¡y test
echo Hoan thanh test. Nhan phim bat ky de thoat.  # HoÃ n thÃ nh
pause  # Chá»
endlocal  # Káº¿t thÃºc
```

Giáº£i thÃ­ch chi tiáº¿t:

- TÆ°Æ¡ng tá»± nhÆ° 02_run_train.bat nhÆ°ng cháº¡y test_model.py.

### requirements.txt

Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t.

```text
tensorflow>=2.13.0  # TensorFlow version má»›i nháº¥t
keras>=2.13.0  # Keras tÆ°Æ¡ng thÃ­ch
numpy>=1.21.0  # NumPy cho tÃ­nh toÃ¡n
pandas>=1.3.0  # Pandas cho data manipulation
scikit-learn>=1.0.0  # Scikit-learn cho ML utilities
matplotlib>=3.5.0  # Matplotlib cho plotting
seaborn>=0.11.0  # Seaborn cho statistical plots
pillow>=8.0.0  # Pillow cho image processing
keras-tuner>=1.3.5  # Keras Tuner cho hyperparameter tuning
```

Giáº£i thÃ­ch chi tiáº¿t:

- TensorFlow: Framework chÃ­nh cho deep learning.
- Keras: API high-level cho TensorFlow.
- NumPy: ThÆ° viá»‡n tÃ­nh toÃ¡n sá»‘ há»c.
- Pandas: Xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng báº£ng.
- Scikit-learn: Thuáº­t toÃ¡n ML vÃ  metrics.
- Matplotlib/Seaborn: Visualization.
- Pillow: Xá»­ lÃ½ áº£nh.
- Keras-tuner: Tá»‘i Æ°u hyperparameters (máº·c dÃ¹ khÃ´ng dÃ¹ng trong code hiá»‡n táº¡i).

---

<a id="9-training-testing-result-reporting-process"></a>
## 9. QUY TRÃŒNH HUáº¤N LUYá»†N, KIá»‚M TRA & BÃO CÃO Káº¾T QUáº¢

### Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

- Rescale vá» [0,1], augmentation (shift ngang/dá»c 10%), resize vá» 256x256
- Loáº¡i bá» áº£nh lá»—i, kiá»ƒm tra sá»‘ lÆ°á»£ng tá»«ng class

### XÃ¢y dá»±ng mÃ´ hÃ¬nh

- Base model: Xception (pretrained ImageNet, freeze/unfreeze layer)
- CÃ¡c lá»›p bá»• sung: GlobalAveragePooling2D, Dense(1024, relu), BatchNormalization, Dropout(0.2), Dense(5, softmax)

### Huáº¥n luyá»‡n 2 giai Ä‘oáº¡n

1. Giai Ä‘oáº¡n 1: Freeze base model, train top layers
2. Giai Ä‘oáº¡n 2: Unfreeze 35 lá»›p cuá»‘i, fine-tune vá»›i learning rate tháº¥p hÆ¡n
3. Callbacks: EarlyStopping, ReduceLROnPlateau

### ÄÃ¡nh giÃ¡

- Accuracy, loss, classification report, confusion matrix, vÃ­ dá»¥ dá»± Ä‘oÃ¡n
- LÆ°u log tá»«ng láº§n cháº¡y vÃ o `app_log/`

---

<a id="10-example-outputs-logs-confusion-matrix-sample-prediction"></a>
## 10. VÃ Dá»¤ Äáº¦U RA, LOG, CONFUSION MATRIX, SAMPLE PREDICTION

### VÃ­ dá»¥ log huáº¥n luyá»‡n

```text
2025-11-08_14-30-12 | Epoch 1/30 | loss: 0.45 | acc: 0.87 | val_loss: 0.52 | val_acc: 0.85
2025-11-08_14-30-12 | EarlyStopping triggered after 12 epochs
Model saved to kaggle/working/art_styles/art_style_classifier.h5
```

### VÃ­ dá»¥ bÃ¡o cÃ¡o kiá»ƒm tra

```text
Test accuracy: 0.91
Test loss: 0.38
Classification report:
              precision    recall  f1-score   support
    Baroque       0.92      0.90      0.91       200
    ...
Confusion matrix:
[[180  10  ...]
 [  5 190 ...]
 ...]
```

### VÃ­ dá»¥ dá»± Ä‘oÃ¡n

```text
File: test/Baroque/img_001.jpg | True: Baroque | Pred: Baroque | Prob: 0.98
File: test/Cubism/img_002.jpg  | True: Cubism  | Pred: Expressionism | Prob: 0.67
```

---

<a id="11-troubleshooting-performance-tuning"></a>
## 11. TROUBLESHOOTING & PERFORMANCE TUNING

### Lá»—i thÆ°á»ng gáº·p

- **Lá»—i khÃ´ng tÃ¬m tháº¥y Python**: CÃ i Python, kiá»ƒm tra biáº¿n PATH
- **Lá»—i thiáº¿u thÆ° viá»‡n**: Äáº£m báº£o Ä‘Ã£ cháº¡y `pip install -r requirements.txt`
- **Lá»—i dá»¯ liá»‡u**: Kiá»ƒm tra láº¡i cáº¥u trÃºc thÆ° má»¥c, tÃªn class, sá»‘ lÆ°á»£ng áº£nh
- **Lá»—i khÃ´ng cháº¡y Ä‘Æ°á»£c lá»‡nh `code`**: ThÃªm Ä‘Æ°á»ng dáº«n VS Code vÃ o PATH
- **Lá»—i commit Git**: Sá»­ dá»¥ng `git commit -m "message"` hoáº·c kiá»ƒm tra editor
- **Lá»—i CUDA/cuDNN**: Kiá»ƒm tra version, biáº¿n mÃ´i trÆ°á»ng, cÃ i Ä‘Ãºng báº£n phÃ¹ há»£p vá»›i TensorFlow

### Debug & tá»‘i Æ°u hÃ³a

- Sá»­ dá»¥ng log chi tiáº¿t trong `app_log/` Ä‘á»ƒ kiá»ƒm tra quÃ¡ trÃ¬nh huáº¥n luyá»‡n
- Kiá»ƒm tra GPU báº±ng lá»‡nh `tf.config.list_physical_devices('GPU')`
- TÄƒng batch size náº¿u RAM/GPU Ä‘á»§ lá»›n
- Giáº£m sá»‘ epoch náº¿u overfitting
- Thá»­ cÃ¡c thuáº­t toÃ¡n augmentation khÃ¡c

### Performance tuning

- Sá»­ dá»¥ng mixed precision náº¿u GPU há»— trá»£
- Chuyá»ƒn sang mÃ´ hÃ¬nh EfficientNet náº¿u cáº§n tá»‘c Ä‘á»™/Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n
- Sá»­ dá»¥ng TensorBoard Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh huáº¥n luyá»‡n

---

<a id="12-best-practices-environment-management"></a>
## 12. BEST PRACTICES & QUáº¢N LÃ MÃ”I TRÆ¯á»œNG

- LuÃ´n sá»­ dá»¥ng mÃ´i trÆ°á»ng áº£o (venv) cho tá»«ng project
- Quáº£n lÃ½ version code báº±ng git, commit thÆ°á»ng xuyÃªn
- Backup dá»¯ liá»‡u, mÃ´ hÃ¬nh, log Ä‘á»‹nh ká»³
- Äáº·t tÃªn file, folder rÃµ rÃ ng, nháº¥t quÃ¡n
- Chá»‰ sá»­a Ä‘Æ°á»ng dáº«n, class trong `constants.py` Ä‘á»ƒ trÃ¡nh lá»—i lan truyá»n
- Ghi chÃº, comment code Ä‘áº§y Ä‘á»§, giáº£i thÃ­ch tá»«ng bÆ°á»›c
- Sá»­ dá»¥ng batch file cho ngÆ°á»i dÃ¹ng cuá»‘i, script Python cho developer
- Kiá»ƒm tra log sau má»—i láº§n huáº¥n luyá»‡n/test Ä‘á»ƒ phÃ¡t hiá»‡n lá»—i sá»›m

---

<a id="13-references-contact-contributions"></a>
## 13. TÃ€I LIá»†U THAM KHáº¢O, LIÃŠN Há»†, ÄÃ“NG GÃ“P

- [Google Drive data](https://drive.google.com/file/d/10FkuSbGvZTCURyoKs_JEbBUnFgDFL102/view?usp=sharing)
- [Video cÃ i Python](https://www.youtube.com/watch?v=W99c8zVOkkg)
- [TÃ i liá»‡u TensorFlow](https://www.tensorflow.org/)
- [TÃ i liá»‡u Keras](https://keras.io/)
- [TÃ i liá»‡u vá» Xception](https://arxiv.org/abs/1610.02357)
- [TÃ i liá»‡u vá» Data Augmentation](https://keras.io/api/preprocessing/image/)
- [TÃ i liá»‡u vá» Transfer Learning](https://www.tensorflow.org/tutorials/images/transfer_learning)

### LiÃªn há»‡

- Náº¿u cÃ³ cÃ¢u há»i hoáº·c cáº§n há»— trá»£, vui lÃ²ng kiá»ƒm tra code vÃ  comments trong script
- ÄÃ³ng gÃ³p, bÃ¡o lá»—i, Ä‘á» xuáº¥t tÃ­nh nÄƒng má»›i qua GitHub Issues

---

<a id="14-detailed-code-flow-diagrams"></a>
## 14. SÆ  Äá»’ CHI TIáº¾T CÃC LUá»’NG Xá»¬ LÃ TRONG CODE

### 1. SÆ¡ Ä‘á»“ tá»•ng quan Pipeline Huáº¥n luyá»‡n (Training Pipeline Diagram)

```mermaid
graph TD
    A[Import thÆ° viá»‡n vÃ  constants] --> B[Thiáº¿t láº­p logging vÃ  redirect stdout]
    B --> C[Kiá»ƒm tra vÃ  chia dá»¯ liá»‡u náº¿u cáº§n]
    C --> D[Táº¡o ImageDataGenerator cho train/validation]
    D --> E[Táº¡o generators tá»« thÆ° má»¥c]
    E --> F[XÃ¢y dá»±ng mÃ´ hÃ¬nh Xception + custom layers]
    F --> G[Compile mÃ´ hÃ¬nh vá»›i Adam optimizer]
    G --> H[Thiáº¿t láº­p callbacks: EarlyStopping, ReduceLROnPlateau]
    H --> I[Huáº¥n luyá»‡n giai Ä‘oáº¡n 1: Freeze base model]
    I --> J[Unfreeze 35 layers cuá»‘i, recompile vá»›i LR tháº¥p]
    J --> K[Huáº¥n luyá»‡n giai Ä‘oáº¡n 2: Fine-tuning]
    K --> L[LÆ°u mÃ´ hÃ¬nh vÃ o file .h5]
    L --> M[HoÃ n thÃ nh training]
```

**Giáº£i thÃ­ch:** SÆ¡ Ä‘á»“ nÃ y mÃ´ táº£ toÃ n bá»™ quy trÃ¬nh tá»« import Ä‘áº¿n lÆ°u mÃ´ hÃ¬nh trong `train_model.py`. Má»—i bÆ°á»›c Ä‘Æ°á»£c thá»±c hiá»‡n tuáº§n tá»± Ä‘á»ƒ Ä‘áº£m báº£o mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n hiá»‡u quáº£ vá»›i transfer learning.

### 2. SÆ¡ Ä‘á»“ Kiáº¿n trÃºc MÃ´ hÃ¬nh (Model Architecture Diagram)

```mermaid
graph TD
    A[Input Image 256x256x3] --> B[Xception Base Model<br/>Pre-trained on ImageNet<br/>Freeze/Unfreeze layers]
    B --> C[Global Average Pooling 2D]
    C --> D[Dense 1024<br/>ReLU Activation]
    D --> E[Batch Normalization]
    E --> F[Dropout 0.2]
    F --> G[Dense 5<br/>Softmax Activation]
    G --> H[Output: Probabilities<br/>for 5 Art Styles]
```

**Giáº£i thÃ­ch:** Kiáº¿n trÃºc mÃ´ hÃ¬nh tá»« input Ä‘áº¿n output, sá»­ dá»¥ng Xception lÃ m base vá»›i cÃ¡c layer custom Ä‘á»ƒ phÃ¢n loáº¡i 5 phong cÃ¡ch nghá»‡ thuáº­t.

### 3. SÆ¡ Ä‘á»“ Luá»“ng Dá»¯ liá»‡u (Data Flow Diagram)

```mermaid
graph TD
    A["kaggle/input/wikiart/"] --> B["data_collector.py<br/>collect_data_if_needed()"]
    B --> C["create_directories()<br/>Táº¡o thÆ° má»¥c train/validate/test"]
    C --> D["split_data()<br/>Chia dá»¯ liá»‡u 80/10/10"]
    D --> E["kaggle/working/art_styles/<br/>train/validate/test/"]
    E --> F["train_model.py<br/>ImageDataGenerator.flow_from_directory()"]
    F --> G["Generators cho training/validation"]
```

**Giáº£i thÃ­ch:** Luá»“ng xá»­ lÃ½ dá»¯ liá»‡u tá»« thÆ° má»¥c gá»‘c Ä‘áº¿n viá»‡c táº¡o generators cho huáº¥n luyá»‡n, Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c chia vÃ  tiá»n xá»­ lÃ½ Ä‘Ãºng cÃ¡ch.

### 4. SÆ¡ Ä‘á»“ VÃ²ng láº·p Huáº¥n luyá»‡n (Training Loop Flowchart)

```mermaid
flowchart TD
    A[Start Training] --> B{Epoch < 10?}
    B -->|Yes| C[Fit model giai Ä‘oáº¡n 1<br/>Freeze base model]
    B -->|No| D{Epoch < 50?}
    D -->|Yes| E[Fit model giai Ä‘oáº¡n 2<br/>Unfreeze layers]
    D -->|No| F[End Training]
    C --> G[Check callbacks<br/>EarlyStopping/ReduceLR]
    E --> G
    G --> H{Continue?}
    H -->|Yes| I[Next Epoch]
    H -->|No| F
    I --> B
```

**Giáº£i thÃ­ch:** VÃ²ng láº·p huáº¥n luyá»‡n vá»›i 2 giai Ä‘oáº¡n, callbacks kiá»ƒm soÃ¡t quÃ¡ trÃ¬nh Ä‘á»ƒ trÃ¡nh overfitting vÃ  tá»‘i Æ°u learning rate.

### 5. SÆ¡ Ä‘á»“ Pipeline Kiá»ƒm tra (Evaluation Pipeline)

```mermaid
graph TD
    A["Load model tá»« file .h5"] --> B["Táº¡o test generator<br/>shuffle=False"]
    B --> C["Evaluate trÃªn validation<br/>TÃ­nh accuracy/loss"]
    C --> D["Predict trÃªn test set<br/>Láº¥y y_pred_prob"]
    D --> E["TÃ­nh y_pred = argmax(y_pred_prob)"]
    E --> F["Táº¡o classification_report<br/>precision/recall/f1"]
    F --> G["Táº¡o confusion_matrix<br/>vÃ  heatmap"]
    G --> H["Gá»i display_image_grid()<br/>Hiá»ƒn thá»‹ áº£nh máº«u"]
    H --> I["HoÃ n thÃ nh evaluation"]
```

**Giáº£i thÃ­ch:** Quy trÃ¬nh kiá»ƒm tra mÃ´ hÃ¬nh tá»« load model Ä‘áº¿n xuáº¥t bÃ¡o cÃ¡o vÃ  visualization trong `test_model.py`.

### 6. SÆ¡ Ä‘á»“ VÃ²ng Ä‘á»i MÃ´ hÃ¬nh (Model Lifecycle Diagram)

```mermaid
stateDiagram-v2
    [*] --> DataPreparation: Chia dá»¯ liá»‡u
    DataPreparation --> ModelBuilding: XÃ¢y dá»±ng Xception
    ModelBuilding --> TrainingPhase1: Huáº¥n luyá»‡n giai Ä‘oáº¡n 1
    TrainingPhase1 --> FineTuning: Fine-tuning giai Ä‘oáº¡n 2
    FineTuning --> ModelSaving: LÆ°u mÃ´ hÃ¬nh .h5
    ModelSaving --> Evaluation: Kiá»ƒm tra trÃªn test
    Evaluation --> Deployment: Chuyá»ƒn sang TFLite
    Deployment --> [*]
    Evaluation --> Retraining: Náº¿u cáº§n cáº£i thiá»‡n
    Retraining --> TrainingPhase1
```

**Giáº£i thÃ­ch:** VÃ²ng Ä‘á»i mÃ´ hÃ¬nh tá»« chuáº©n bá»‹ dá»¯ liá»‡u Ä‘áº¿n triá»ƒn khai, vá»›i kháº£ nÄƒng retraining náº¿u cáº§n.

### 7. SÆ¡ Ä‘á»“ Tiá»n xá»­ lÃ½ Dá»¯ liá»‡u (Preprocessing Pipeline Diagram)

```mermaid
graph TD
    A[Raw Images] --> B[ImageDataGenerator<br/>rescale=1./255]
    B --> C[Resize to 256x256]
    C --> D{Is Training?}
    D -->|Yes| E[Augmentation:<br/>width_shift_range=0.1<br/>height_shift_range=0.1<br/>fill_mode='nearest']
    D -->|No| F[No augmentation]
    E --> G[Batch Generation]
    F --> G
    G --> H[Feed to Model]
```

**Giáº£i thÃ­ch:** Pipeline tiá»n xá»­ lÃ½ áº£nh vá»›i augmentation chá»‰ cho training set Ä‘á»ƒ tÄƒng Ä‘a dáº¡ng dá»¯ liá»‡u.

### 8. SÆ¡ Ä‘á»“ Triá»ƒn khai (Deployment Diagram)

```mermaid
graph TD
    A[Trained Model .h5] --> B[Convert to TFLite<br/>tflite_model.tflite]
    B --> C[Create labels.txt<br/>Mapping index to style names]
    C --> D[Deploy to Mobile/Web App]
    D --> E[User uploads image]
    E --> F[Preprocess image<br/>256x256, rescale]
    F --> G[Run inference<br/>on device]
    G --> H[Return predicted style<br/>with confidence]
```

**Giáº£i thÃ­ch:** Quy trÃ¬nh chuyá»ƒn mÃ´ hÃ¬nh tá»« training sang deployment trÃªn mobile/web vá»›i TensorFlow Lite.

### 9. SÆ¡ Ä‘á»“ Chia dá»¯ liá»‡u (Data Splitting Flow)

```mermaid
flowchart TD
    A[Main Directory] --> B[List all files<br/>Check size > 0]
    B --> C{Len > max_files?}
    C -->|Yes| D[Limit to max_files]
    C -->|No| E[Use all files]
    D --> F[train_test_split<br/>train_size=0.8]
    E --> F
    F --> G[Train files 80%]
    F --> H[Remaining 20%]
    H --> I[train_test_split<br/>test_size=0.5]
    I --> J[Validate files 10%]
    I --> K[Test files 10%]
    G --> L[Copy to train/]
    J --> M[Copy to validate/]
    K --> N[Copy to test/]
```

**Giáº£i thÃ­ch:** Chi tiáº¿t cÃ¡ch chia dá»¯ liá»‡u trong `data_collector.py` vá»›i kiá»ƒm tra lá»—i vÃ  giá»›i háº¡n sá»‘ lÆ°á»£ng.

### 10. SÆ¡ Ä‘á»“ Augmentation Process

```mermaid
graph TD
    A[Original Image] --> B[Rescale 1./255]
    B --> C[Resize 256x256]
    C --> D[Random Width Shift<br/>Â±10%]
    D --> E[Random Height Shift<br/>Â±10%]
    E --> F[Fill Mode: Nearest]
    F --> G[Augmented Image<br/>Ready for training]
```

**Giáº£i thÃ­ch:** Quy trÃ¬nh augmentation Ä‘á»ƒ táº¡o dá»¯ liá»‡u Ä‘a dáº¡ng, chá»‰ Ã¡p dá»¥ng cho training set.

### 11. SÆ¡ Ä‘á»“ Callbacks Flow

```mermaid
flowchart TD
    A[Training Epoch] --> B[Calculate val_loss]
    B --> C{EarlyStopping<br/>patience=10}
    C -->|val_loss improved| D[Continue training]
    C -->|No improvement<br/>for 10 epochs| E[Stop training<br/>Restore best weights]
    B --> F{ReduceLROnPlateau<br/>patience=3}
    F -->|val_loss improved| D
    F -->|No improvement<br/>for 3 epochs| G[Reduce LR by factor 0.1]
    G --> D
```

**Giáº£i thÃ­ch:** CÃ¡ch callbacks hoáº¡t Ä‘á»™ng Ä‘á»ƒ kiá»ƒm soÃ¡t quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  trÃ¡nh overfitting.

### 12. SÆ¡ Ä‘á»“ Confusion Matrix Generation

```mermaid
graph TD
    A["y_true from generator.classes"] --> B["y_pred = argmax(predict_prob)"]
    B --> C["confusion_matrix(y_true, y_pred)"]
    C --> D["Create figure 8x6"]
    D --> E["sns.heatmap()<br/>annot=True, fmt='d'<br/>cmap='Blues'"]
    E --> F["Set labels<br/>xticklabels, yticklabels"]
    F --> G["plt.show()"]
```

**Giáº£i thÃ­ch:** Quy trÃ¬nh táº¡o vÃ  hiá»ƒn thá»‹ confusion matrix Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t phÃ¢n loáº¡i.

### 13. SÆ¡ Ä‘á»“ Prediction Loop

```mermaid
flowchart TD
    A["For each test image"] --> B["Load and resize to 256x256"]
    B --> C["Convert to array / 255"]
    C --> D["Expand dims for batch"]
    D --> E["model.predict()"]
    E --> F["np.amax() for confidence"]
    F --> G["np.argmax() for class index"]
    G --> H["Map index to style name"]
    H --> I["Compare with actual style"]
    I --> J["Color: green if correct, red if wrong"]
    J --> K["Create title with info"]
    K --> L["Display image with title"]
```

**Giáº£i thÃ­ch:** VÃ²ng láº·p dá»± Ä‘oÃ¡n trong hÃ m `display_image_grid()` Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£ trá»±c quan.

### 14. SÆ¡ Ä‘á»“ Logging Setup

```mermaid
graph TD
    A["os.makedirs(LOG_DIR)"] --> B["datetime.now().strftime()"]
    B --> C["log_file = join(LOG_DIR, session_time)"]
    C --> D["logging.basicConfig()<br/>level=INFO<br/>format=time+level+message<br/>handlers=FileHandler+StreamHandler"]
    D --> E["class LoggerWriter<br/>__init__(logger, level)<br/>write(message)<br/>flush()"]
    E --> F["sys.stdout = LoggerWriter(INFO)"]
    F --> G["sys.stderr = LoggerWriter(ERROR)"]
```

**Giáº£i thÃ­ch:** CÃ¡ch thiáº¿t láº­p logging Ä‘á»ƒ ghi láº¡i toÃ n bá»™ output vÃ o file theo timestamp.

### 15. SÆ¡ Ä‘á»“ Model Compilation

```mermaid
graph TD
    A["model.compile()"] --> B["optimizer='adam'"]
    B --> C["loss='categorical_crossentropy'"]
    C --> D["metrics=['accuracy']"]
    D --> E["Phase 1: Freeze base model"]
    E --> F["Phase 2: Unfreeze layers<br/>optimizer=Adam(lr=1e-4)"]
```

**Giáº£i thÃ­ch:** Hai láº§n compile mÃ´ hÃ¬nh cho hai giai Ä‘oáº¡n huáº¥n luyá»‡n vá»›i tham sá»‘ khÃ¡c nhau.

### 16. SÆ¡ Ä‘á»“ Generator Creation

```mermaid
graph TD
    A["ImageDataGenerator()"] --> B{"rescale=1./255"}
    B --> C{"For training:<br/>width_shift_range=0.1<br/>height_shift_range=0.1<br/>fill_mode='nearest'"}
    B --> D{"For validation:<br/>No augmentation"}
    C --> E["flow_from_directory()<br/>directory=train/<br/>target_size=256x256<br/>batch_size=64<br/>class_mode='categorical'"]
    D --> F["flow_from_directory()<br/>directory=validate/<br/>target_size=256x256<br/>batch_size=64<br/>class_mode='categorical'"]
```

**Giáº£i thÃ­ch:** CÃ¡ch táº¡o generators khÃ¡c nhau cho training vÃ  validation vá»›i augmentation phÃ¹ há»£p.

### 17. SÆ¡ Ä‘á»“ Error Handling in Data Collection

```mermaid
flowchart TD
    A["collect_data_if_needed()"] --> B{"Check train/validate/test exist?"}
    B -->|No| C["create_directories()"]
    B -->|Yes| D{"Directories empty?"}
    D -->|Yes| C
    D -->|No| E["Print: Data already split"]
    C --> F["For each style"]
    F --> G["split_data()"]
    G --> H["Check main_dir exists"]
    H -->|No| I["Log error, return"]
    H -->|Yes| J["Check split_size valid"]
    J -->|No| K["Log error, return"]
    J -->|Yes| L["Get file list, filter valid"]
    L --> M{"len > max_files?"}
    M -->|Yes| N["Limit files"]
    M -->|No| O["Use all"]
    N --> P["train_test_split 0.8"]
    O --> P
    P --> Q["Copy train files"]
    P --> R["train_test_split remaining 0.5"]
    R --> S["Copy validate files"]
    R --> T["Copy test files"]
```

**Giáº£i thÃ­ch:** Xá»­ lÃ½ lá»—i toÃ n diá»‡n trong viá»‡c chia dá»¯ liá»‡u Ä‘á»ƒ Ä‘áº£m báº£o robustness.

### 18. SÆ¡ Ä‘á»“ Model Saving Flow

```mermaid
graph TD
    A["Training completed"] --> B["model.save()<br/>path = join(OUTPUT_BASE_DIR, MODEL_FILENAME)"]
    B --> C["Print success message<br/>with full path"]
    C --> D["Model ready for testing<br/>or deployment"]
```

**Giáº£i thÃ­ch:** ÄÆ¡n giáº£n nhÆ°ng quan trá»ng: lÆ°u mÃ´ hÃ¬nh sau khi training xong.

### 19. SÆ¡ Ä‘á»“ Batch File Execution (02_run_train.bat)

```mermaid
flowchart TD
    A[Run 02_run_train.bat] --> B[python --version]
    B --> C{Errorlevel == 1?}
    C -->|Yes| D[Print error message<br/>Link to install video<br/>Exit 1]
    C -->|No| E{if not exist env<br/>python -m venv env}
    E --> F[call env\Scripts\activate.bat]
    F --> G{if exist requirements.txt<br/>pip install -r requirements.txt<br/>else print error}
    G --> H{if not exist train_model.py<br/>print error, exit 1}
    H --> I[python train_model.py]
    I --> J[echo Training completed<br/>pause]
```

**Giáº£i thÃ­ch:** Luá»“ng thá»±c thi cá»§a batch file Ä‘á»ƒ tá»± Ä‘á»™ng setup environment vÃ  cháº¡y training.

### 20. SÆ¡ Ä‘á»“ Visualization Flow

```mermaid
graph TD
    A["display_image_grid()"] --> B["Calculate num_rows, num_cols"]
    B --> C["plt.subplots(num_rows, num_cols)"]
    C --> D["For i in range(n)"]
    D --> E["Random choice style dir"]
    E --> F["Random choice image file"]
    F --> G["image.load_img(target_size=256x256)"]
    G --> H["img_to_array / 255<br/>expand_dims"]
    H --> I["model.predict()"]
    I --> J["np.amax, np.argmax"]
    J --> K["Map to style name<br/>Compare actual vs predicted"]
    K --> L{"is_correct?"}
    L -->|Yes| M["title_color = 'green'"]
    L -->|No| N["title_color = 'red'"]
    M --> O["Create title string"]
    N --> O
    O --> P["ax.imshow(image)<br/>ax.set_title(title, color)<br/>ax.axis('off')"]
    P --> Q["plt.tight_layout()<br/>plt.show()"]
```

**Giáº£i thÃ­ch:** Quy trÃ¬nh táº¡o visualization vá»›i mÃ u sáº¯c Ä‘á»ƒ dá»… dÃ ng Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh.

### 21. SÆ¡ Ä‘á»“ Import Flow

```mermaid
graph TD
    A[Start train_model.py] --> B[Import standard libs<br/>numpy, os, datetime]
    B --> C[Import TF/Keras<br/>models, layers, optimizers]
    C --> D[Import device_lib<br/>Print devices]
    D --> E[Import sys, datetime<br/>for logging setup]
    E --> F[Import constants<br/>DATA_BASE_DIR, etc.]
    F --> G[Try import data_collector<br/>Else print message]
    G --> H[Setup logging<br/>Create log file]
    H --> I[Redirect stdout/stderr]
    I --> J[Continue to data collection]
```

**Giáº£i thÃ­ch:** Thá»© tá»± import vÃ  setup ban Ä‘áº§u trong script training.

### 22. SÆ¡ Ä‘á»“ Memory Management

```mermaid
graph TD
    A[Large dataset] --> B[ImageDataGenerator<br/>flow_from_directory]
    B --> C[Batch processing<br/>batch_size=64]
    C --> D[GPU memory allocation<br/>TensorFlow manages]
    D --> E[Callbacks monitor<br/>val_loss for early stopping]
    E --> F[Model saved periodically<br/>if needed]
```

**Giáº£i thÃ­ch:** CÃ¡ch quáº£n lÃ½ bá»™ nhá»› khi xá»­ lÃ½ dataset lá»›n vá»›i batch processing.

---

> **LÆ°u Ã½:** File README nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ vá»«a hÆ°á»›ng dáº«n chi tiáº¿t cho ngÆ°á»i má»›i, vá»«a lÃ m tÃ i liá»‡u tham kháº£o cho developer, giÃºp triá»ƒn khai, má»Ÿ rá»™ng, báº£o trÃ¬ dá»± Ã¡n dá»… dÃ ng. CÃ¡c sÆ¡ Ä‘á»“ trÃªn giÃºp visualize cÃ¡c luá»“ng xá»­ lÃ½ phá»©c táº¡p trong code.